name: Multi-Model Provenance Verification CI

on:
  push:
    branches: [ main, develop, master ]
  pull_request:
    branches: [ main, master ]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM
  workflow_dispatch:  # Allow manual triggering

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'

jobs:
  # Formal proof verification
  coq-proofs:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Install Coq
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y coq
          coqc --version
          
      - name: Fix src/proofs permissions
        run: chmod -R u+w src/proofs
        
      - name: Remove existing Makefile if present
        run: rm -f src/proofs/Makefile
        
      - name: Verify mathematical proofs
        run: |
          cd src/proofs
          coq_makefile -f _CoqProject -o Makefile
          make
          mkdir -p build
          cp *.vo build/ 2>/dev/null || true
            
      - name: Extract to OCaml
        run: |
          cd src/proofs
          coqc provenance_extraction.v
          mkdir -p build
          cp *.ml *.mli build/ 2>/dev/null || true
          
      - name: Upload proof artifacts
        uses: actions/upload-artifact@v4
        with:
          name: coq-proofs
          path: src/proofs/build/*.vo

  # Core system testing
  core-tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']
        
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          
      - name: Upgrade build tools
        run: pip install --upgrade pip setuptools==68.2.2 wheel cython==0.29.36
        
      - name: Install minimal dependencies only
        run: |
          # Bypass requirements-dev.txt entirely to avoid cython_sources issues
          pip install -r requirements-minimal.txt
          echo "Installed minimal dependencies to avoid build issues"
          
      - name: Run unit tests
        run: |
          pytest tests/unit/ -v
          
      - name: Run integration tests
        run: |
          pytest tests/integration/ -v
          
      - name: Upload coverage
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml

  # Multi-model LLM testing (simplified)
  llm-model-matrix:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          - model_provider: openai
            model_name: gpt-4o-mini
          - model_provider: anthropic  
            model_name: claude-3-5-haiku-20241022
            
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Install testing framework
        run: |
          pip install --upgrade pip setuptools==68.2.2 wheel cython==0.29.36
          pip install promptfoo deepeval evidently
          npm install -g promptfoo
          
      - name: Configure model access
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          QWEN_API_KEY: ${{ secrets.QWEN_API_KEY }}
          DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
        run: |
          echo "Testing with ${{ matrix.model_provider }}/${{ matrix.model_name }}"
          
      - name: Run claim detection tests
        run: |
          python tests/model_testing/test_claim_detection.py \
            --model-provider ${{ matrix.model_provider }} \
            --model-name ${{ matrix.model_name }}
            
      - name: Run evidence verification tests  
        run: |
          python tests/model_testing/test_evidence_verification.py \
            --model-provider ${{ matrix.model_provider }} \
            --model-name ${{ matrix.model_name }}
            
      - name: Upload model test results
        uses: actions/upload-artifact@v4
        with:
          name: model-results-${{ matrix.model_provider }}-${{ matrix.model_name }}
          path: test-results/

  # AI Coding Assistant Integration Tests (simplified)
  ai-assistant-matrix:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          - assistant: claude-code
            test_scenario: basic_claim_detection
          - assistant: cursor
            test_scenario: basic_claim_detection
          
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup test environment
        run: |
          pip install --upgrade pip setuptools==68.2.2 wheel cython==0.29.36
          pip install -r requirements-minimal.txt
          
      - name: Run assistant integration tests
        env:
          AI_ASSISTANT: ${{ matrix.assistant }}
          TEST_SCENARIO: ${{ matrix.test_scenario }}
        run: |
          python tests/assistant_integration/test_${{ matrix.test_scenario }}.py \
            --assistant ${{ matrix.assistant }}
            
      - name: Generate compatibility report
        run: |
          python scripts/generate_compatibility_report.py \
            --assistant ${{ matrix.assistant }} \
            --scenario ${{ matrix.test_scenario }}

  # Performance benchmarking
  performance-tests:
    runs-on: ubuntu-latest  # Use regular runner to avoid availability issues
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup performance environment
        run: |
          pip install --upgrade pip setuptools==68.2.2 wheel cython==0.29.36
          pip install -r requirements-minimal.txt
          pip install pytest-benchmark memory-profiler
          
      - name: Run performance benchmarks from existing tests
        run: |
          python tests/assistant_integration/test_performance_benchmarks.py --assistant claude-code
          echo "Performance test completed - no specific benchmark files needed"
          
      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: performance-benchmarks
          path: "*.json"
        if: always()  # Upload even if no files found

  # Security and safety testing
  security-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup security testing
        run: |
          pip install --upgrade pip setuptools==68.2.2 wheel cython==0.29.36
          pip install -r requirements-minimal.txt
          pip install bandit safety semgrep
          
      - name: Run static security analysis
        run: |
          bandit -r src/ -f json -o bandit-results.json || true
          safety check --json --output safety-results.json || true
          semgrep --config=auto --json --output=semgrep-results.json src/ || true
          
      - name: Test for prompt injection vulnerabilities
        run: |
          python tests/security/test_prompt_injection.py
          
      - name: Test evidence tampering protection
        run: |
          python tests/security/test_evidence_tampering.py
          
      - name: Upload security results
        uses: actions/upload-artifact@v4
        with:
          name: security-results
          path: "*-results.json"

  # Real-world integration testing
  integration-tests:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
          
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup integration environment
        run: |
          pip install -r requirements-minimal.txt
          
      - name: Test Claude Code hook integration
        run: |
          python tests/integration/test_claude_code_hooks.py
          
      - name: Test MCP server integration
        run: |
          python tests/integration/test_mcp_server.py
          
      - name: Test end-to-end workflows
        run: |
          python tests/integration/test_e2e_workflows.py

  # Generate comprehensive report
  report-generation:
    needs: [coq-proofs, core-tests, llm-model-matrix, ai-assistant-matrix, performance-tests, security-tests, integration-tests]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
          
      - name: Generate comprehensive CI report
        run: |
          python scripts/generate_ci_report.py \
            --artifacts-dir artifacts/ \
            --output-dir reports/
            
      - name: Upload final report
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-ci-report
          path: reports/
          
      - name: Comment on PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('reports/summary.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });

  # Deploy to staging on main branch
  deploy-staging:
    needs: [coq-proofs, core-tests, llm-model-matrix, ai-assistant-matrix, performance-tests, security-tests, integration-tests]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Deploy to staging environment
        env:
          DEPLOY_KEY: ${{ secrets.STAGING_DEPLOY_KEY }}
        run: |
          python scripts/deploy_staging.py
          
      - name: Run smoke tests on staging
        run: |
          python tests/smoke/test_staging_deployment.py